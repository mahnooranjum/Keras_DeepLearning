{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARTIFICIAL NEURAL NETWORK TUNING AND IMPROVEMENT\n",
    "Welcome to this tutorial. In this tutorial we will tune parameters and apply various improvement techniques to achieve the highest accuracy in the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 6: TUNING AND IMPROVING THE ANN\n",
    "\n",
    "Let's talk about precision and accuracy for a moment. \n",
    "\n",
    "The Precision-Accuracy trade off turns deep learning into artistry.\n",
    "\n",
    "Imagine the red points as model accuracy. The model's accuracy might depict high variance i.e low precision when retrained. \n",
    "\n",
    "This causes inaccurate model predictions. How do we battle this? BY K-FOLD CROSS VALIDATION. \n",
    "\n",
    "#### K-FOLD CROSS VALIDATION:\n",
    "In this technique:\n",
    "1. We split the training set into k folds.\n",
    "2. We train the model with k-1 folds.\n",
    "3. We test the model with 1 fold.\n",
    "\n",
    "We chose the k-1 and the test fold randomly.\n",
    "\n",
    "\n",
    " <img src='pva.png' width=\"700\"> \n",
    "Image taken from [http://cdn.antarcticglaciers.org/]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Var1  Var2  Var3  Var4  Var5  Var6   Var7  Var8  Labels\n",
       "0     6   148    72    35     0  33.6  0.627    50       1\n",
       "1     1    85    66    29     0  26.6  0.351    31       0\n",
       "2     8   183    64     0     0  23.3  0.672    32       1\n",
       "3     1    89    66    23    94  28.1  0.167    21       0\n",
       "4     0   137    40    35   168  43.1  2.288    33       1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('../Datasets/diabetes.csv')\n",
    "X = dataset.iloc[:, 0:8].values\n",
    "y = dataset.iloc[:, 8].values\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\py35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "614/614 [==============================] - 0s 526us/step - loss: 0.6873 - acc: 0.6417\n",
      "Epoch 2/50\n",
      "614/614 [==============================] - 0s 146us/step - loss: 0.6488 - acc: 0.6726\n",
      "Epoch 3/50\n",
      "614/614 [==============================] - 0s 141us/step - loss: 0.5699 - acc: 0.7638\n",
      "Epoch 4/50\n",
      "614/614 [==============================] - 0s 141us/step - loss: 0.5172 - acc: 0.7590\n",
      "Epoch 5/50\n",
      "614/614 [==============================] - 0s 140us/step - loss: 0.4979 - acc: 0.7622\n",
      "Epoch 6/50\n",
      "614/614 [==============================] - 0s 140us/step - loss: 0.4894 - acc: 0.7606\n",
      "Epoch 7/50\n",
      "614/614 [==============================] - 0s 140us/step - loss: 0.4846 - acc: 0.7704\n",
      "Epoch 8/50\n",
      "614/614 [==============================] - 0s 145us/step - loss: 0.4826 - acc: 0.7671\n",
      "Epoch 9/50\n",
      "614/614 [==============================] - 0s 141us/step - loss: 0.4807 - acc: 0.7655\n",
      "Epoch 10/50\n",
      "614/614 [==============================] - 0s 138us/step - loss: 0.4786 - acc: 0.7671\n",
      "Epoch 11/50\n",
      "614/614 [==============================] - 0s 143us/step - loss: 0.4774 - acc: 0.7687\n",
      "Epoch 12/50\n",
      "614/614 [==============================] - 0s 143us/step - loss: 0.4766 - acc: 0.7655\n",
      "Epoch 13/50\n",
      "614/614 [==============================] - 0s 140us/step - loss: 0.4758 - acc: 0.7736\n",
      "Epoch 14/50\n",
      "614/614 [==============================] - 0s 143us/step - loss: 0.4753 - acc: 0.7720\n",
      "Epoch 15/50\n",
      "614/614 [==============================] - 0s 140us/step - loss: 0.4744 - acc: 0.7687\n",
      "Epoch 16/50\n",
      "614/614 [==============================] - 0s 140us/step - loss: 0.4737 - acc: 0.7785\n",
      "Epoch 17/50\n",
      "614/614 [==============================] - 0s 140us/step - loss: 0.4732 - acc: 0.7687\n",
      "Epoch 18/50\n",
      "614/614 [==============================] - 0s 141us/step - loss: 0.4726 - acc: 0.7769\n",
      "Epoch 19/50\n",
      "614/614 [==============================] - 0s 141us/step - loss: 0.4720 - acc: 0.7752\n",
      "Epoch 20/50\n",
      "614/614 [==============================] - 0s 141us/step - loss: 0.4717 - acc: 0.7736\n",
      "Epoch 21/50\n",
      "614/614 [==============================] - 0s 141us/step - loss: 0.4711 - acc: 0.7752\n",
      "Epoch 22/50\n",
      "614/614 [==============================] - 0s 140us/step - loss: 0.4711 - acc: 0.7736\n",
      "Epoch 23/50\n",
      "614/614 [==============================] - 0s 145us/step - loss: 0.4708 - acc: 0.7720\n",
      "Epoch 24/50\n",
      "614/614 [==============================] - 0s 144us/step - loss: 0.4705 - acc: 0.7720\n",
      "Epoch 25/50\n",
      "614/614 [==============================] - 0s 141us/step - loss: 0.4704 - acc: 0.7720\n",
      "Epoch 26/50\n",
      "614/614 [==============================] - 0s 141us/step - loss: 0.4699 - acc: 0.7671\n",
      "Epoch 27/50\n",
      "614/614 [==============================] - 0s 143us/step - loss: 0.4696 - acc: 0.7687\n",
      "Epoch 28/50\n",
      "614/614 [==============================] - 0s 143us/step - loss: 0.4686 - acc: 0.7720\n",
      "Epoch 29/50\n",
      "614/614 [==============================] - 0s 140us/step - loss: 0.4688 - acc: 0.7752\n",
      "Epoch 30/50\n",
      "614/614 [==============================] - 0s 141us/step - loss: 0.4679 - acc: 0.7687\n",
      "Epoch 31/50\n",
      "614/614 [==============================] - 0s 141us/step - loss: 0.4677 - acc: 0.7671\n",
      "Epoch 32/50\n",
      "614/614 [==============================] - 0s 141us/step - loss: 0.4687 - acc: 0.7687\n",
      "Epoch 33/50\n",
      "614/614 [==============================] - 0s 141us/step - loss: 0.4673 - acc: 0.7687\n",
      "Epoch 34/50\n",
      "614/614 [==============================] - 0s 143us/step - loss: 0.4666 - acc: 0.7736\n",
      "Epoch 35/50\n",
      "614/614 [==============================] - 0s 140us/step - loss: 0.4668 - acc: 0.7736\n",
      "Epoch 36/50\n",
      "614/614 [==============================] - 0s 145us/step - loss: 0.4662 - acc: 0.7704\n",
      "Epoch 37/50\n",
      "614/614 [==============================] - 0s 143us/step - loss: 0.4663 - acc: 0.7687\n",
      "Epoch 38/50\n",
      "614/614 [==============================] - 0s 139us/step - loss: 0.4652 - acc: 0.7704\n",
      "Epoch 39/50\n",
      "614/614 [==============================] - 0s 143us/step - loss: 0.4658 - acc: 0.7736\n",
      "Epoch 40/50\n",
      "614/614 [==============================] - 0s 143us/step - loss: 0.4652 - acc: 0.7736\n",
      "Epoch 41/50\n",
      "614/614 [==============================] - 0s 141us/step - loss: 0.4644 - acc: 0.7736\n",
      "Epoch 42/50\n",
      "614/614 [==============================] - 0s 141us/step - loss: 0.4638 - acc: 0.7736\n",
      "Epoch 43/50\n",
      "614/614 [==============================] - 0s 139us/step - loss: 0.4640 - acc: 0.7687\n",
      "Epoch 44/50\n",
      "614/614 [==============================] - 0s 141us/step - loss: 0.4639 - acc: 0.7704\n",
      "Epoch 45/50\n",
      "614/614 [==============================] - 0s 143us/step - loss: 0.4631 - acc: 0.7752\n",
      "Epoch 46/50\n",
      "614/614 [==============================] - 0s 143us/step - loss: 0.4630 - acc: 0.7752\n",
      "Epoch 47/50\n",
      "614/614 [==============================] - 0s 143us/step - loss: 0.4632 - acc: 0.7736\n",
      "Epoch 48/50\n",
      "614/614 [==============================] - 0s 141us/step - loss: 0.4626 - acc: 0.7720\n",
      "Epoch 49/50\n",
      "614/614 [==============================] - 0s 141us/step - loss: 0.4620 - acc: 0.7687\n",
      "Epoch 50/50\n",
      "614/614 [==============================] - 0s 140us/step - loss: 0.4617 - acc: 0.7720\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "# Initialize the ANN object\n",
    "classifier = Sequential() \n",
    "# Creating the first hidden layer with inputs\n",
    "# Units = 8+1/2 = 4.5 = 5\n",
    "classifier.add(Dense(units = 5, kernel_initializer = 'uniform', activation = 'relu', input_dim = np.shape(X)[1]))\n",
    "# Creating the second hidden layer\n",
    "classifier.add(Dense(units = 5, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "# Creating the output layer\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "# Compiling the model\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "# Fitting on the training set\n",
    "classifier.fit(X_train, y_train, batch_size = 5, epochs = 50)\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "def build_classifier():\n",
    "    # classifier = Sequential()\n",
    "    classifier.add(Dense(units = 5, kernel_initializer = 'uniform', activation = 'relu', input_dim = 8))\n",
    "    classifier.add(Dense(units = 5, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, epochs = 100)\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10, n_jobs = -1)\n",
    "    mean = accuracies.mean()\n",
    "    variance = accuracies.std()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 7: DROPOUT REGULARIZATION\n",
    "So what is dropout regularization? \n",
    "\n",
    "Deep learning models, like machine learning models can observe overfitting. When we have large networks, combining different predictions and simple test-trial parameter tuning can be costly. Dropout is a technique for addressing the problem of overfitting.\n",
    "\n",
    "1. Dropping random neurons from the networks in each iteration. \n",
    "2. Now our neurons are not as \"adapted\" or \"dependent\" on each other.\n",
    "3. Once the model is trained, we can easily average our network weights on different thinned networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 8: PARAMETER TUNING VIA GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "def build_classifier(optimizer):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 5, kernel_initializer = 'uniform', activation = 'relu', input_dim = 8))\n",
    "    classifier.add(Dense(units = 5, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier)\n",
    "parameters = {'batch_size': [5, 10,15],\n",
    "              'epochs': [100, 200],\n",
    "              'optimizer': ['adam', 'rmsprop', 'sgd']}\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WELCOME TO THE END OF THE TUTORIAL\n",
    "\n",
    "Hope you enjoyed this tutorial just as much as I enjoyed coding it. \n",
    "\n",
    "---------------------------------------------------------------------------------------\n",
    "Copyrights Â© 2018, All Rights Reserved.\n",
    "- Author: Mahnoor Anjum.\n",
    "- Course: The Complete Hands-On Machine Learning Course\n",
    "- Date Created: 2018-07-18\n",
    "- Date Modified: -"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
